# Remove duplicates [SPARK]
## Description
This Task uses PySpark to remove duplicate rows from a CSV file and writes the deduplicated data to an output file. It reads the input file, drops the duplicate rows, and writes the resulting dataframe to the output file.

## Inputs
- `input` - Input CSV file with header

## Outputs
- `output` - Output CSV file with deduplicated data and header

## Dependencies
- PySpark
- Container Image: `impeccableai/spark-py:spark-k8s-bitnami`
- Packages: `com.amazonaws:aws-java-sdk-pom:1.11.956`, `org.apache.hadoop:hadoop-aws:3.3.1`

## Execution
The Task is executed as a Spark job with the following main app file and arguments:
- Main App File: `{{ script_path }}`
- App Arguments: `--input {{ input }} --output {{ output }}`

<sub>Content of this file was (partially) generated by ChatGPT4. Apologies for all inconsistencies and inaccurate data.</sub>